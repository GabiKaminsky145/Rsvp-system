# ğŸ’Œ RSVP System via WhatsApp + LLM (Hebrew Support)

A full-stack WhatsApp bot to manage wedding RSVPs â€” complete with typo-tolerant Hebrew understanding using a local LLM via [Ollama](https://ollama.com).  
Built for Gabriel & Ortalâ€™s wedding ğŸ‰

---

## âœ¨ Features

- âœ… Sends RSVP invitations with media over WhatsApp  
- âœ… Interprets Hebrew replies (even with typos!) using a local LLM (`mistral` or `gemma`)  
- âœ… Records responses in PostgreSQL (`yes` / `no` / `maybe`)  
- âœ… Asks for number of attendees if response is "yes"  
- âœ… Automatically retries guests who havenâ€™t responded  
- âœ… Runs 24/7 on a GCP VM using `pm2`  

---

## ğŸ“¸ Demo

Coming soon â€” sample screenshots of guest interaction

---

## ğŸ§± Project Structure

```bash
Rsvp-system/
â”œâ”€â”€ index.js               # Main WhatsApp bot logic
â”œâ”€â”€ llmHelper.js           # LLM intent classification (via Ollama)
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ db.js              # Database helper functions
â”œâ”€â”€ wedding invitation.png # Media sent to guests
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## âš™ï¸ Requirements

- Node.js 16+
- PostgreSQL database
- A WhatsApp number to use with [whatsapp-web.js](https://github.com/pedroslopez/whatsapp-web.js)
- A Linux VM (tested on GCP e2-standard-2)
- [Ollama](https://ollama.com) installed on the server (supports mistral/gemma/llama3)
- `pm2` for background services

---

## ğŸš€ Getting Started

### 1. Clone the Project

```bash
git clone https://github.com/GabiKaminsky145/Rsvp-system.git
cd Rsvp-system
npm install
```

### 2. Configure PostgreSQL

Set up your tables and credentials in `shared/db.js`.

You should have tables like:

```sql
CREATE TABLE guests (...);
CREATE TABLE rsvps (...);
```

### 3. Install and Run Ollama (LLM)

#### Install Ollama:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### Download a model (e.g., mistral):

```bash
ollama pull mistral
```

#### Start the model:

```bash
ollama run mistral
```

> Ollama listens on `http://localhost:11434`

### 4. Start the Bot with PM2

Install PM2 if you havenâ€™t:

```bash
npm install -g pm2
```

Start both services:

```bash
pm2 start "ollama run mistral" --name ollama-llm
pm2 start index.js --name rsvp-bot
pm2 save
pm2 startup
```

Then follow the instructions to enable auto-start on boot.

---

## ğŸ’¬ How It Works

1. The bot sends RSVP WhatsApp messages to all guests.
2. Guests can reply with
   - `1`, `××’×™×¢`, `×›×Ÿ` â†’ interpreted as "Yes"
   - `2`, `×œ× ××’×™×¢`, `×œ×` â†’ interpreted as "No"
   - `3`, `××•×œ×™` â†’ interpreted as "Maybe"
   - Or typoed text like `××’×™×`, `××•×•×œ×™×™×™` â†’ LLM will try to classify
3. If the answer is "yes", the bot will ask how many are coming.
4. All responses are saved in your database.

---

## ğŸ›  Testing LLM Manually

You can test your model like this:

```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistral",
    "prompt": "×”×•×“×¢×ª ×”××•×¨×—: \"××’×™×\"\n×ª×©×•×‘×ª×š:"
  }'
```

Expected Output:
```text
×›×Ÿ
```

---

## ğŸ§  Tips & Notes

- Make sure `ollama` is always running (use PM2!)
- You can switch the model to `gemma` or `llama3` in `llmHelper.js`
- If a guest replies again, they must type `"×”×ª×—×œ×”"` to reset their response

---

## ğŸ§ª Example Conversation

```text
Guest: ××’×™×  
Bot: ×›××” ×ª×’×™×¢×•?  
Guest: 3  
Bot: ×ª×•×“×” ×¨×‘×”! ğŸ“… ××¤×©×¨ ×œ×”×•×¡×™×£ ××ª ×”×—×ª×•× ×” ×œ×™×•××Ÿ ×©×œ×š...
```
---

## ğŸ§‘â€ğŸ’» Author

Built by [Gabi Kaminsky](https://github.com/GabiKaminsky145)

